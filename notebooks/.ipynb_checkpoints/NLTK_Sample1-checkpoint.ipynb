{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import os\n",
    "from nltk.corpus import gutenberg\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk import pos_tag\n",
    "from itertools import islice\n",
    "from nltk.tokenize import sent_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package gutenberg to\n",
      "[nltk_data]     /Users/manitraranaivoharison/nltk_data...\n",
      "[nltk_data]   Package gutenberg is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/manitraranaivoharison/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/manitraranaivoharison/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('gutenberg')\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moby Dick sample: The pale Usher--threadbare in coat, heart, body, and brain; I see him\n",
      "now.  He was ever dusting his old lexicons and grammars, with a queer\n",
      "handkerchief, mockingly embellished with \n"
     ]
    }
   ],
   "source": [
    "moby_dick = gutenberg.raw('melville-moby_dick.txt')\n",
    "print('Moby Dick sample: {0}'.format(moby_dick[117:300]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = word_tokenize(moby_dick[117:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_pos = [(word, pos) for word, pos in pos_tag(words)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('The', 'DT')\n",
      "('pale', 'NN')\n",
      "('Usher', 'NNP')\n",
      "('--', ':')\n",
      "('threadbare', 'NN')\n"
     ]
    }
   ],
   "source": [
    "for item in islice(word_pos, 5):\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# moby_dick"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = word_tokenize('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy import displacy\n",
    "nlp = spacy.load('fr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Demain\n",
      "je\n",
      "travaille\n",
      "à\n",
      "la\n",
      "maison\n"
     ]
    }
   ],
   "source": [
    "doc = nlp('Demain je travaille à la maison')\n",
    "for token in doc:\n",
    "    print(token.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Séparation des phrases\n",
    "sentences = nltk.sent_tokenize(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Séparation des phrases\n",
    "sentences = nltk.sent_tokenize(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Séparation des mots\n",
    "tokenized_sentences = [nltk.word_tokenize(sentence) for sentence in sentences]\n",
    "\n",
    "# Étiquetage morpho-syntaxique\n",
    "tagged_sentences = [nltk.pos_tag(sentence) for sentence in tokenized_sentences]\n",
    "\n",
    "# Application de NER\n",
    "chunked_sentences = nltk.ne_chunk_sents(tagged_sentences, binary=False)\n",
    "\n",
    "entity_names = []\n",
    "for tree in chunked_sentences:\n",
    "    entity_names.extend(extract_entity_names(tree))\n",
    "\n",
    "# Print unique entity names\n",
    "print(set(entity_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  PART 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [sent for sent in sent_tokenize(moby_dick[117:1000])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentences 0: The pale Usher--threadbare in coat, heart, body, and brain; I see him\n",
      "now.\n",
      "sentences 1: He was ever dusting his old lexicons and grammars, with a queer\n",
      "handkerchief, mockingly embellished with all the gay flags of all the\n",
      "known nations of the world.\n",
      "sentences 2: He loved to dust his old grammars; it\n",
      "somehow mildly reminded him of his mortality.\n",
      "sentences 3: \"While you take in hand to school others, and to teach them by what\n",
      "name a whale-fish is to be called in our tongue leaving out, through\n",
      "ignorance, the letter H, which almost alone maketh the signification\n",
      "of the word, you deliver that which is not true.\"\n",
      "sentences 4: --HACKLUYT\n",
      "\n",
      "\"WHALE.\n",
      "sentences 5: ... Sw. and Dan.\n",
      "sentences 6: HVAL.\n",
      "sentences 7: This animal is named from roundness\n",
      "or rolling; for in Dan.\n",
      "sentences 8: HVALT is arched or vaulted.\"\n",
      "sentences 9: --WEBSTER'S\n",
      "DICTIONARY\n",
      "\n",
      "\"WHALE.\n",
      "sentences 10: ...\n",
      "sentences 11: It is more immediately from the Dut.\n",
      "sentences 12: and Ger.\n",
      "sentences 13: WALLEN;\n",
      "A.S. WALW-IAN, to roll, to wallow.\"\n",
      "sentences 14: --RICHARDSON'S DICTIONARY\n"
     ]
    }
   ],
   "source": [
    "for (i, sent) in enumerate(sentences):\n",
    "    print(f'sentences {i}: {sent}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!spacy download fr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('fr_core_news_md')\n",
    "from spacy.lang.fr import French\n",
    "nlp_french = French()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: en_core_web_sm==2.0.0 from https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.0.0/en_core_web_sm-2.0.0.tar.gz#egg=en_core_web_sm==2.0.0 in /miniconda3/envs/py37NLP/lib/python3.7/site-packages (2.0.0)\n",
      "\n",
      "\u001b[93m    Linking successful\u001b[0m\n",
      "    //miniconda3/envs/py37NLP/lib/python3.7/site-packages/en_core_web_sm -->\n",
      "    //miniconda3/envs/py37NLP/lib/python3.7/site-packages/spacy/data/en\n",
      "\n",
      "    You can now load the model via spacy.load('en')\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!spacy download en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_md')\n",
    "from spacy.lang.en import English\n",
    "nlp_english = English()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.pipeline import SentenceSegmenter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nlp_english.add_pipe(nlp_english.create_pipe('sentencizer'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence 0 : The pale Usher--threadbare in coat, heart, body, and brain; I see him\n",
      "now.\n",
      "Sentence 1 :  He was ever dusting his old lexicons and grammars, with a queer\n",
      "handkerchief, mockingly embellished with all the gay flags of all the\n",
      "known nations of the world.\n",
      "Sentence 2 :  He loved to dust his old grammars; it\n",
      "somehow mildly reminded him of his mortality.\n",
      "Sentence 3 : \n",
      "\n",
      "\"While you take in hand to school others, and to teach them by what\n",
      "name a whale-fish is to be called in our tongue leaving out, through\n",
      "ignorance, the letter H, which almost alone maketh the signification\n",
      "of the word, you deliver that which is not true.\"\n",
      "Sentence 4 : --HACKLUYT\n",
      "\n",
      "\"WHALE. ...\n",
      "Sentence 5 : Sw.\n",
      "Sentence 6 : and Dan.\n",
      "Sentence 7 : HVAL.\n",
      "Sentence 8 :  This animal is named from roundness\n",
      "or rolling; for in Dan.\n",
      "Sentence 9 : HVALT is arched or vaulted.\"\n",
      "Sentence 10 : --WEBSTER'S\n",
      "DICTIONARY\n",
      "\n",
      "\"WHALE. ...\n",
      "Sentence 11 : It is more immediately from the Dut.\n",
      "Sentence 12 : and Ger.\n",
      "Sentence 13 : WALLEN;\n",
      "A.S. WALW-IAN, to roll, to wallow.\"\n",
      "Sentence 14 : --RICHARDSON'S DICTIONARY\n",
      "\n",
      "KETOS,               GREEK.\n",
      "Sentence 15 : \n",
      "CETUS,               LATIN.\n",
      "Sentence 16 : \n",
      "WHOEL,               ANGLO-SAXON.\n",
      "Sentence 17 : \n",
      "HVALT,               DANISH.\n",
      "Sentence 18 : \n",
      "WAL,                 DUTCH.\n",
      "Sentence 19 : \n",
      "HWAL,                SWEDISH.\n",
      "Sentence 20 : \n",
      "WHALE,               ICELANDIC.\n",
      "Sentence 21 : \n",
      "WHALE,               ENGLISH.\n",
      "Sentence 22 : \n",
      "BALEINE,             FRENCH.\n",
      "Sentence 23 : \n",
      "BALLENA,             SPANISH.\n",
      "Sentence 24 : \n",
      "PEKEE-NUEE-NUEE,     FEGEE.\n",
      "Sentence 25 : \n",
      "PEKEE-NUEE-NUEE,     ERROMANGOAN.\n",
      "Sentence 26 : \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "EXTRACTS (Supplied by a Sub-Sub-Librarian).\n",
      "Sentence 27 : \n",
      "\n",
      "It will be seen that this mere painstaking burrower and grub-worm of\n",
      "a poor devil of a Sub-Sub appears to have gone through the long\n",
      "Vaticans and street-stalls of the earth, picking up whatever random\n",
      "allusions to whales he could anyways find in any book whatsoever,\n",
      "sacred or profane.\n",
      "Sentence 28 :  Therefore you must not, in every case at least,\n",
      "take the higgledy-piggledy whale statements, however authentic, in\n",
      "these extracts, for veritable gospel cetology.\n",
      "Sentence 29 :  Far from it.\n",
      "Sentence 30 :  As\n",
      "touching the ancient authors generally, as well as the poets here\n",
      "appearing, these extracts are solely valuable or entertaining, as\n",
      "affording a glancing bird's eye view of what has been promiscuously\n",
      "said, thought, fancied, and sung of Leviathan, by many nations and\n",
      "generations, including our own.\n",
      "Sentence 31 : \n",
      "\n",
      "So fare thee well, poor devil of a Sub-Sub, whose commentator I am.\n",
      "Sentence 32 : \n",
      "Thou belongest to that hopeless, sallow tribe which no wine of this\n",
      "world will ever warm; and for whom even Pale Sherry would be too\n",
      "rosy-strong; but with whom one sometimes loves to sit, and feel\n",
      "poor-devilish, too; and grow convivial upon tears; and say to them\n",
      "bluntly, with full eyes and empty glasses, and in not altogether\n",
      "unpleasant sadness--Give it up, Sub-Subs!\n",
      "Sentence 33 :  For by how much the more\n",
      "pains ye take to please the world, by so much the more shall ye for\n",
      "ever go thankless!\n",
      "Sentence 34 :  Would that I could clear out Hampton Court and\n",
      "the Tuileries for ye!\n",
      "Sentence 35 :  But gulp down your tears and hie aloft to the\n",
      "royal-mast with your hearts; for your friends who have gone before\n",
      "are clearing out the seven-storied heavens, a\n"
     ]
    }
   ],
   "source": [
    "doc = nlp_english(moby_dick[117:3000])\n",
    "for i,sentence in enumerate(doc.sents):\n",
    "    print('Sentence {0} : {1}'.format(i,sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join('data','Tokenization - contract 1.txt'),'r', encoding='utf-8') as f:\n",
    "    doc_text_1 = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'THIS SERVICES AGREEMENT is made the 5th day of September 2008\\n\\nBETWEEN:-\\n1.\\tMr. John Smith. whose registered office is at 1 Forge End, Woking, Surrey, GU21 6DB (“Client”) and \\n2.\\tSupplier, plc. (registered in England and Wales under number 943935) whose registered office is at 1 Forge End, Woking, Surrey, GU21 6DB (the “Service Provider”).\\nRECITALS:\\nWHEREAS\\nA.\\tThe Service Provider currently provides certain services to [CLIENT] and certain other parties under and in accordance with an agreement between the parties dated 29 June 2001 (\"Current Agreement\").\\nB.\\t[CLIENT] and the Service Provider wish to replace the Current Agreement with this Agreement. \\nC.\\tThis Agreement sets out the Services (defined below) to be provided by the Service Provider to certain parties identified in this Agreement. The Service Provider has agreed to provide such Services in accordance with and subject to the terms and conditions of this Agreement.\\nIT IS AGREED as follows:\\n1.\\tDEFINITIONS AND INTERPRETATION\\n1.1\\tIn the case of and to the extent of any conflict, inconsistency or ambiguity:-\\n1.1.1\\tbetween:-\\n(a)\\tthese Clauses and Schedule 1 (Definitions); and\\n(b)\\tany other parts of this Agreement, \\nthese Clauses and Schedule 1 (Definitions) shall prevail;\\n1.1.2\\tbetween this Agreement (excluding the Controlled Documents) and any Controlled Document, this Agreement shall prevail;\\n1.1.3\\tbetween:-\\n(a)\\tany Project Terms; and\\n(b)\\tany other parts of this Agreement,\\nunless agreed otherwise by the Parties in writing the provisions of the Project Terms shall prevail in relation to the elements of the Project Terms which relate exclusively to that Project, otherwise the provisions of the rest of the Agreement shall prevail; and\\n'"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_text_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [sent for sent in sent_tokenize(doc_text_1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentences 0 THIS SERVICES AGREEMENT is made the 5th day of September 2008\n",
      "\n",
      "BETWEEN:-\n",
      "1.\n",
      "Sentences 1 Mr. John Smith.\n",
      "Sentences 2 whose registered office is at 1 Forge End, Woking, Surrey, GU21 6DB (“Client”) and \n",
      "2.\n",
      "Sentences 3 Supplier, plc.\n",
      "Sentences 4 (registered in England and Wales under number 943935) whose registered office is at 1 Forge End, Woking, Surrey, GU21 6DB (the “Service Provider”).\n",
      "Sentences 5 RECITALS:\n",
      "WHEREAS\n",
      "A.\n",
      "Sentences 6 The Service Provider currently provides certain services to [CLIENT] and certain other parties under and in accordance with an agreement between the parties dated 29 June 2001 (\"Current Agreement\").\n",
      "Sentences 7 B.\n",
      "Sentences 8 [CLIENT] and the Service Provider wish to replace the Current Agreement with this Agreement.\n",
      "Sentences 9 C.\tThis Agreement sets out the Services (defined below) to be provided by the Service Provider to certain parties identified in this Agreement.\n",
      "Sentences 10 The Service Provider has agreed to provide such Services in accordance with and subject to the terms and conditions of this Agreement.\n",
      "Sentences 11 IT IS AGREED as follows:\n",
      "1.\n",
      "Sentences 12 DEFINITIONS AND INTERPRETATION\n",
      "1.1\tIn the case of and to the extent of any conflict, inconsistency or ambiguity:-\n",
      "1.1.1\tbetween:-\n",
      "(a)\tthese Clauses and Schedule 1 (Definitions); and\n",
      "(b)\tany other parts of this Agreement, \n",
      "these Clauses and Schedule 1 (Definitions) shall prevail;\n",
      "1.1.2\tbetween this Agreement (excluding the Controlled Documents) and any Controlled Document, this Agreement shall prevail;\n",
      "1.1.3\tbetween:-\n",
      "(a)\tany Project Terms; and\n",
      "(b)\tany other parts of this Agreement,\n",
      "unless agreed otherwise by the Parties in writing the provisions of the Project Terms shall prevail in relation to the elements of the Project Terms which relate exclusively to that Project, otherwise the provisions of the rest of the Agreement shall prevail; and\n"
     ]
    }
   ],
   "source": [
    "for (i,sent) in enumerate(sentences):\n",
    "    print(f'Sentences {i} {sent}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join('data','Tokenization - contract 2.txt'),'r', encoding='utf-8') as f:\n",
    "    doc_text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'MASTER SERVICES AGREEMENT\\n \\nThis Master Services Agreement (the “Agreement”) is entered into as of April 27th, 2015 (the “Effective Date”) by and between Accelerated Pharma Inc. with a place of business at 15W15581st, Burr Ridge 60527 Illinois, USA (“Accelerated”), and Heraeus Precious Metals GmbH & Co. KG, a German limited liability company with a principal place of business located at Heraeusstr. 12- 14, 63450 Hanau, Germany (“Manufacturer” or “Heraeus”), each singly a “Party” and together, the “Parties.”\\n \\nRECITALS\\n \\nAccelerated intends to entrust Heraeus with the manufacture of the active pharmaceutical ingredient Picoplatin which is required by Accelerated for a clinical development program.\\n \\nNOW, THEREFORE, the Parties agree as follows:'"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [sent for sent in sent_tokenize(doc_text)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentences 0 MASTER SERVICES AGREEMENT\n",
      " \n",
      "This Master Services Agreement (the “Agreement”) is entered into as of April 27th, 2015 (the “Effective Date”) by and between Accelerated Pharma Inc. with a place of business at 15W15581st, Burr Ridge 60527 Illinois, USA (“Accelerated”), and Heraeus Precious Metals GmbH & Co. KG, a German limited liability company with a principal place of business located at Heraeusstr.\n",
      "Sentences 1 12- 14, 63450 Hanau, Germany (“Manufacturer” or “Heraeus”), each singly a “Party” and together, the “Parties.”\n",
      " \n",
      "RECITALS\n",
      " \n",
      "Accelerated intends to entrust Heraeus with the manufacture of the active pharmaceutical ingredient Picoplatin which is required by Accelerated for a clinical development program.\n",
      "Sentences 2 NOW, THEREFORE, the Parties agree as follows:\n"
     ]
    }
   ],
   "source": [
    "for (i,sent) in enumerate(sentences):\n",
    "    print(f'Sentences {i} {sent}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import starmap, chain\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_pattern = re.compile(\n",
    "    r\"\"\"\n",
    "    (\\n\\W*\\([A-z]+\\))\n",
    "    |\n",
    "    (\\n\\W*\\([0-9]+\\))\n",
    "    |\n",
    "    (\\n\\W+\\n)\n",
    "    (\\n([0-9]+\\.)+)\"\"\",flags=re.DOTALL and re.VERBOSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join('data','Tokenization - contract 2.txt'),'r', encoding='utf-8') as f:\n",
    "    doc_text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "splits = sentence_pattern.finditer(doc_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<callable_iterator at 0x1a84ef1dd0>"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices = om"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
